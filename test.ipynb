{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_2.shape: torch.Size([2, 4, 4])\n",
      "a_2: tensor([[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "         [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "         [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "         [ 0.1198,  1.2377,  1.1168, -0.2473]],\n",
      "\n",
      "        [[-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "         [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "         [ 0.7502, -0.5855, -0.1734,  0.1835],\n",
      "         [ 1.3894,  1.5863,  0.9463, -0.8437]]], device='cuda:0')\n",
      "a_3.shape: torch.Size([4, 2, 2])\n",
      "a_3: tensor([[[-0.3348,  0.1299],\n",
      "         [-0.6727,  0.6423]],\n",
      "\n",
      "        [[-0.6857,  0.9376],\n",
      "         [ 0.2548,  0.0281]],\n",
      "\n",
      "        [[-0.7969,  0.7015],\n",
      "         [ 0.0478,  0.7782]],\n",
      "\n",
      "        [[-0.6648,  0.5771],\n",
      "         [-1.0863,  0.9076]]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "a_2_t.shape: torch.Size([2, 4, 4])\n",
      "a_2_t: tensor([[[-0.1936, -0.3475,  0.2451,  0.1020],\n",
      "         [ 0.1234,  0.5338,  0.0554, -0.4155],\n",
      "         [ 0.0434, -0.6266,  0.0666,  0.3864],\n",
      "         [-0.2092,  0.5872,  0.3101, -0.1719]],\n",
      "\n",
      "        [[-0.0848, -0.8420,  0.1196,  0.3943],\n",
      "         [-0.0645, -0.3145,  0.1188, -0.2206],\n",
      "         [ 0.2573, -0.7505, -0.0363,  0.4399],\n",
      "         [ 0.1864,  0.1313, -0.1258, -0.0887]]], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "random = torch.manual_seed(0)\n",
    "\n",
    "# make activation shape [bs, 128, 28, 28]\n",
    "a_2 = torch.randn(2, 4, 4).cuda()\n",
    "print(f\"a_2.shape: {a_2.shape}\")\n",
    "print(f\"a_2: {a_2}\")\n",
    "\n",
    "# make weight [c_in, c_out, k_h, k_w]\n",
    "conv_2 = nn.Conv2d(2, 4, kernel_size=3, stride=2, padding=1).cuda()\n",
    "\n",
    "# forward pass\n",
    "a_3 = conv_2(a_2)\n",
    "print(f\"a_3.shape: {a_3.shape}\")\n",
    "print(\"a_3:\", a_3)\n",
    "\n",
    "# restore a_2 used a_3, conv_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_2.shape: torch.Size([2, 4, 4])\n",
      "a_2: tensor([[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "         [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "         [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "         [ 0.1198,  1.2377,  1.1168, -0.2473]],\n",
      "\n",
      "        [[-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "         [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "         [ 0.7502, -0.5855, -0.1734,  0.1835],\n",
      "         [ 1.3894,  1.5863,  0.9463, -0.8437]]], device='cuda:0')\n",
      "a_3.shape: torch.Size([4, 2, 2])\n",
      "a_3: tensor([[[-0.3348,  0.1299],\n",
      "         [-0.6727,  0.6423]],\n",
      "\n",
      "        [[-0.6857,  0.9376],\n",
      "         [ 0.2548,  0.0281]],\n",
      "\n",
      "        [[-0.7969,  0.7015],\n",
      "         [ 0.0478,  0.7782]],\n",
      "\n",
      "        [[-0.6648,  0.5771],\n",
      "         [-1.0863,  0.9076]]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "a_2_approx.shape: torch.Size([2, 4, 4])\n",
      "a_2_approx: tensor([[[-0.1683, -0.3222,  0.2704,  0.1273],\n",
      "         [ 0.1487,  0.5591,  0.0806, -0.3902],\n",
      "         [ 0.0687, -0.6013,  0.0919,  0.4117],\n",
      "         [-0.1839,  0.6125,  0.3353, -0.1466]],\n",
      "\n",
      "        [[-0.1341, -0.8913,  0.0702,  0.3450],\n",
      "         [-0.1138, -0.3638,  0.0695, -0.2700],\n",
      "         [ 0.2080, -0.7999, -0.0856,  0.3905],\n",
      "         [ 0.1370,  0.0819, -0.1752, -0.1380]]], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Original a_2: tensor([[[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "         [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "         [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "         [ 0.1198,  1.2377,  1.1168, -0.2473]],\n",
      "\n",
      "        [[-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "         [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "         [ 0.7502, -0.5855, -0.1734,  0.1835],\n",
      "         [ 1.3894,  1.5863,  0.9463, -0.8437]]], device='cuda:0')\n",
      "Difference (L2 norm): 4.762057781219482\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 시드 고정\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# a_2 생성\n",
    "a_2 = torch.randn(2, 4, 4).cuda()\n",
    "print(f\"a_2.shape: {a_2.shape}\")\n",
    "print(f\"a_2: {a_2}\")\n",
    "\n",
    "# Conv2d 정의\n",
    "conv_2 = nn.Conv2d(2, 4, kernel_size=3, stride=2, padding=1).cuda()\n",
    "\n",
    "# Forward pass\n",
    "a_3 = conv_2(a_2)\n",
    "print(f\"a_3.shape: {a_3.shape}\")\n",
    "print(\"a_3:\", a_3)\n",
    "\n",
    "# ConvTranspose2d 정의 (역연산을 위한 설정)\n",
    "conv_transpose_2 = nn.ConvTranspose2d(\n",
    "    4, 2, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    ").cuda()\n",
    "\n",
    "# conv_2의 가중치를 그대로 사용 (단순 근사)\n",
    "conv_transpose_2.weight.data = conv_2.weight.data.clone()\n",
    "\n",
    "# a_3를 이용해 a_2 근사 복구\n",
    "a_2_approx = conv_transpose_2(a_3)\n",
    "print(f\"a_2_approx.shape: {a_2_approx.shape}\")\n",
    "print(f\"a_2_approx: {a_2_approx}\")\n",
    "\n",
    "# 원래 a_2와 비교\n",
    "print(f\"Original a_2: {a_2}\")\n",
    "print(f\"Difference (L2 norm): {torch.norm(a_2 - a_2_approx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
